{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import testCases\n",
    "from dnn_utils import sigmoid, sigmoid_backward, relu, relu_backward\n",
    "import lr_utils\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[ 0.01744812 -0.00761207  0.00319039]\n",
      " [-0.0024937   0.01462108 -0.02060141]]\n",
      "b1 = [[0.]\n",
      " [0.]]\n",
      "W2 = [[-0.00322417 -0.00384054]]\n",
      "b2 = [[0.]]\n"
     ]
    }
   ],
   "source": [
    "#初始化参数(2 layers nn)\n",
    "\n",
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \n",
    "    W1 = np.random.randn(n_h, n_x) * 0.01\n",
    "    b1 = np.zeros((n_h, 1))\n",
    "    W2 = np.random.randn(n_y, n_h) * 0.01\n",
    "    b2 = np.zeros((n_y, 1))\n",
    "    \n",
    "    parameters = {\n",
    "        \"W1\": W1,\n",
    "        \"b1\": b1,\n",
    "        \"W2\": W2,\n",
    "        \"b2\": b2\n",
    "    }\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "#测试\n",
    "parameters = initialize_parameters(3,2,1)\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[ 1.78862847  0.43650985  0.09649747 -1.8634927  -0.2773882 ]\n",
      " [-0.35475898 -0.08274148 -0.62700068 -0.04381817 -0.47721803]\n",
      " [-1.31386475  0.88462238  0.88131804  1.70957306  0.05003364]\n",
      " [-0.40467741 -0.54535995 -1.54647732  0.98236743 -1.10106763]]\n",
      "b1 = [[-1.18504653]\n",
      " [-0.2056499 ]\n",
      " [ 1.48614836]\n",
      " [ 0.23671627]]\n",
      "W2 = [[-1.02378514 -0.7129932   0.62524497 -0.16051336]\n",
      " [-0.76883635 -0.23003072  0.74505627  1.97611078]\n",
      " [-1.24412333 -0.62641691 -0.80376609 -2.41908317]]\n",
      "b2 = [[-0.92379202]\n",
      " [-1.02387576]\n",
      " [ 1.12397796]]\n"
     ]
    }
   ],
   "source": [
    "#初始化参数 （deep nn）\n",
    "\n",
    "def initialize_parameters_deep(layers_dims):\n",
    "    \"\"\"\n",
    "    parameters:\n",
    "        layers_dims: 包含网络中每个图层的节点数量的列表\n",
    "    return：\n",
    "        parameters: 包含\"W1\",\"b1\",\"W2\",\"b2\"..的字典\n",
    "                    Wl -  (layers_dims[l],layers_dims[l-1])\n",
    "                    bl -  (layers_dims[l], 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layers_dims)\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        parameters[\"W\" + str(l)] = np.random.randn(layers_dims[l], layers_dims[l - 1])\n",
    "        parameters[\"b\" + str(l)] = np.random.randn(layers_dims[l], 1)\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "#测试\n",
    "layers_dims = [5,4,3]\n",
    "parameters = initialize_parameters_deep(layers_dims)\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid，A = [[0.03109977 0.88986711]]\n",
      "ReLU，A = [[3.43896131 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 前向传播 (2 layers nn)\n",
    "\n",
    "def linear_forward(A,W,b):\n",
    "    \n",
    "    Z = np.dot(W,A) + b\n",
    "    \n",
    "    cache = (A,W,b)\n",
    "    \n",
    "    return Z, cache\n",
    "\n",
    "def linear_activation_forward(A_prev,W,b,activation):\n",
    "    \"\"\"\n",
    "    parameters: \n",
    "        A_prev: 来自上一层的激活\n",
    "        W：     偏重矩阵\n",
    "        b:      偏向量\n",
    "        activation: 本层使用的激活函数名\n",
    "    return：\n",
    "        A： 激活函数的输出\n",
    "        cache：一个包含“linear_cache”和“activation_cache”的字典\n",
    "    \"\"\"\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = linear_forward(A_prev,W,b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    elif activation == \"relu\":\n",
    "        Z, linear_cache = linear_forward(A_prev,W,b)\n",
    "        A, activation_cache = relu(Z)\n",
    "    \n",
    "    cache = (linear_cache,activation_cache)\n",
    "    \n",
    "    return A, cache\n",
    "\n",
    "#测试\n",
    "A_prev, W,b = testCases.linear_activation_forward_test_case()\n",
    "\n",
    "A, linear_activation_cache = linear_activation_forward(A_prev, W, b, activation = \"sigmoid\")\n",
    "print(\"sigmoid，A = \" + str(A))\n",
    "\n",
    "A, linear_activation_cache = linear_activation_forward(A_prev, W, b, activation = \"relu\")\n",
    "print(\"ReLU，A = \" + str(A))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AL = [[0.92843149 0.8872984 ]\n",
      " [0.57871451 0.4546487 ]\n",
      " [0.63659865 0.51530219]]\n",
      "caches 的长度为 = 2\n"
     ]
    }
   ],
   "source": [
    "# 前向传播 （deep layers nn）\n",
    "def L_model_forward(X, parameters):\n",
    "    \"\"\"\n",
    "    parameter：\n",
    "        X - 数据，numpy数组，维度为（输入节点数量，示例数）\n",
    "        parameters - initialize_parameters_deep（）的输出\n",
    "    \n",
    "    返回：\n",
    "        AL - 最后的激活值\n",
    "        caches - 包含以下内容的缓存列表：\n",
    "                 linear_relu_forward（）的每个cache（有L-1个，索引为从0到L-2）\n",
    "                 linear_sigmoid_forward（）的cache（只有一个，索引为L-1）\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2\n",
    "    for l in range(1, L):\n",
    "        A_prev = A\n",
    "        A, cache = linear_activation_forward(A_prev,parameters[\"W\"+str(l)],parameters[\"b\"+str(l)],\"relu\")\n",
    "        caches.append(cache)\n",
    "    \n",
    "    AL, cache = linear_activation_forward(A, parameters[\"W\"+str(L)],parameters[\"b\"+str(l)],\"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    \n",
    "    return AL,caches\n",
    "#测试\n",
    "X,parameters = testCases.L_model_forward_test_case()\n",
    "AL,caches = L_model_forward(X,parameters)\n",
    "print(\"AL = \" + str(AL))\n",
    "print(\"caches 的长度为 = \" + str(len(caches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = 0.414931599615397\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 计算成本\n",
    "\n",
    "def compute_cost(AL, Y):\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "    cost = -np.sum(np.multiply(np.log(AL),Y) + np.multiply(np.log(1 - AL), 1 - Y)) / m\n",
    "    \n",
    "    cost = np.squeeze(cost)\n",
    "    \n",
    "    return cost\n",
    "\n",
    "#测试\n",
    "Y,AL = testCases.compute_cost_test_case()\n",
    "print(\"cost = \" + str(compute_cost(AL, Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 反向传播\n",
    "\n",
    "def linear_backward(dZ,cache):\n",
    "    \n",
    "    A_prev,W,b = cache\n",
    "    m = A_pre.shape[1]\n",
    "    dW = np.dot(dZ, A_pre.T) / m\n",
    "    db = np.sum(dZ,axis=1,keepdims=True) / m\n",
    "    dA_pre = np.dot(W.T, dZ)\n",
    "    \n",
    "    return dA_prev,dW,db\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
